{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the rating given to a restaurant based solely on the given review text and title using NLP custom primitives.\n",
    "\n",
    "<a style=\"margin:30px\" href=\"https://www.featuretools.com\">\n",
    "    <img width=50% src=\"https://www.featuretools.com/wp-content/uploads/2017/12/FeatureLabs-Logo-Tangerine-800.png\" alt=\"Featuretools\" />\n",
    "</a>\n",
    "\n",
    "**As customers visit places such as restaurants, they will oftentimes leave a review of some sort. Using data from TripAdvisor, we investigate how this textual, unstructured data can be used to predict the overall thoughts of the customer on that restuarant or other place, represented in a star rating.**\n",
    "\n",
    "In this tutorial, we show how [Featuretools](https://www.featuretools.com) can be used to create custom Natural Language Processing features to then be used in feature engingeering to train an accurate machine learning model to predict the customer's rating based on the text of their review.\n",
    "\n",
    "*Note: If you are running this notebook yourself, refer to the read me on Github for instructions to download the Instacart dataset*\n",
    "\n",
    "## Highlights\n",
    "\n",
    "* We create custom primitives to create structured data from unstructured, hard to parse, textual data\n",
    "* We build a pipeline that it can be reused for numerous NLP prediction problems (You can try this yourself!)\n",
    "* We use pretrained models as well as some self-trained models to get the highest accuracy possible on this limited dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featuretools version 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helpers\n",
    "\n",
    "from featuretools.primitives.base.transform_primitive_base import (\n",
    "    TransformPrimitive\n",
    ")\n",
    "from featuretools.primitives import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "dtk = TreebankWordDetokenizer()\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "embed = hub.Module(module_url)\n",
    "\n",
    "print('Featuretools version {}'.format(ft.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load Data\n",
    "We start by loading in the data from our machine. This data is from a kaggle dataset, and instuctions on how to download it can be found in the read me on github. In this data, we only use one set: the set of reviews for each restaurant, that is formatted as a single table with a couple fields: the title of the review, the text of the review, the number of stars the reviewer gave, the price of the restaurant, and the date the review was submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>price</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great drinks and food</td>\n",
       "      <td>They have great local craft beers and probably...</td>\n",
       "      <td>2016-03-28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good food &amp;amp; beer</td>\n",
       "      <td>We went to the downtown SF location. The resta...</td>\n",
       "      <td>2016-03-27</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pretty good beers</td>\n",
       "      <td>I just came to this place for drinks with an o...</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridiculously overpriced (yes I live in SF)</td>\n",
       "      <td>Mediocre food (not bad, just mediocre, you can...</td>\n",
       "      <td>2016-03-08</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Team dinner</td>\n",
       "      <td>We headed out for our team dinner to this esta...</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brewery</td>\n",
       "      <td>Came here with my wife from Colorado for some ...</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                       Great drinks and food   \n",
       "1                        Good food &amp; beer   \n",
       "2                           Pretty good beers   \n",
       "3  Ridiculously overpriced (yes I live in SF)   \n",
       "4                                 Team dinner   \n",
       "5                                     Brewery   \n",
       "\n",
       "                                                text       date  stars price  \\\n",
       "0  They have great local craft beers and probably... 2016-03-28      4     2   \n",
       "1  We went to the downtown SF location. The resta... 2016-03-27      4     2   \n",
       "2  I just came to this place for drinks with an o... 2016-03-16      4     2   \n",
       "3  Mediocre food (not bad, just mediocre, you can... 2016-03-08      3     2   \n",
       "4  We headed out for our team dinner to this esta... 2016-03-01      4     2   \n",
       "5  Came here with my wife from Colorado for some ... 2016-02-23      4     2   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  \n",
       "5      5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = helpers.to_pd_arr(\"rest-reviews.json\")\n",
    "\n",
    "raw_data['index'] = raw_data.index\n",
    "raw_data['date'] = pd.to_datetime(raw_data['date'])\n",
    "raw_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Distribution\n",
    "This is a categorical problem, and we can see here that the data is skewed towards higher reviews, but that there are reviews in every category, from 1-5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13500e4e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = sns.color_palette(\"Blues\")\n",
    "sns.countplot(x=raw_data['stars'], palette = sns.cubehelix_palette(8, start=1, rot=-.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_types = {'index' : vtypes.Index,\n",
    "                  'title': vtypes.Text,\n",
    "                  'text': vtypes.Text,\n",
    "                  'date': vtypes.Datetime,\n",
    "                  'price': vtypes.Categorical}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Split Data\n",
    "In order to avoid label leakage, we want to split the data before performing these operations. So, we will use train test split from the sklearn module to split the data as well as keep the labels for the training and testing (the 'stars' column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw_data.pop('stars')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_data, y, test_size=0.15, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create two different entity sets so that we can create features on each of the sets without leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estrain = ft.EntitySet('Reviews')\n",
    "estest = ft.EntitySet('Reviews')\n",
    "\n",
    "estrain = estrain.entity_from_dataframe(entity_id=\"reviews\",\n",
    "                              dataframe=X_train,\n",
    "                              index='index',\n",
    "                              time_index=\"date\",\n",
    "                              variable_types=variable_types)\n",
    "\n",
    "estest = estest.entity_from_dataframe(entity_id=\"reviews\",\n",
    "                              dataframe=X_test,\n",
    "                              index='index',\n",
    "                              time_index=\"date\",\n",
    "                              variable_types=variable_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Create Custom Features\n",
    "Here, we will create custom features so that we can have some Natural Language Processing Features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create simple features that focus more on the literal text and the punctuation more than the meaning behind the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitleCount(TransformPrimitive):\n",
    "    \"\"\"Computes the number of title words in a document/string\"\"\"\n",
    "    \n",
    "    name=\"title_word_count\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def title_count(array):\n",
    "            return [len(re.findall(' [A-Z]|^[A-Z]', i)) for i in array]\n",
    "        return title_count\n",
    "    \n",
    "class PunctuationCount(TransformPrimitive):\n",
    "    \"\"\"Computes the number of punctuation marks in a document/string\"\"\"\n",
    "    \n",
    "    name=\"punctuation_count\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def punctuation_count(array):\n",
    "            punct = set(string.punctuation)\n",
    "            toks = list(map(word_tokenize, array))\n",
    "            return [sum(map(lambda x: x in punct, y)) for y in toks]\n",
    "        return punctuation_count\n",
    "\n",
    "class StopWordCount(TransformPrimitive):\n",
    "    \"\"\"Computes the number of stop words in a document/string\"\"\"\n",
    "    \n",
    "    name=\"stop_word_count\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def stop_words(array):\n",
    "            swords = set(stopwords.words('english'))\n",
    "            return [sum(map(lambda x: x in swords, word_tokenize(i))) for i in array]\n",
    "        return stop_words\n",
    "    \n",
    "class CapitalCount(TransformPrimitive):\n",
    "    \"\"\"Computes the number of capital letters in a document/string\"\"\"\n",
    "    \n",
    "    name=\"capitals_count\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def capitals(array):\n",
    "            return [len(re.findall('[A-Z]', i)) for i in array]\n",
    "        return capitals\n",
    "\n",
    "class WordCount(TransformPrimitive):\n",
    "    \"\"\"Computes the number of words in a document/string\"\"\"\n",
    "    \n",
    "    name=\"word_count\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def word_count(array):\n",
    "            return [len(word_tokenize(x)) for x in array]\n",
    "        return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create more in depth features, that try to get at the meaning of the text fields. First, we will fit a model based off of the term frequency-inverse document frequency of the training text (and title) data. We will then compose this into a SVD matrix to decrease the number of possible features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('truncatedsvd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=2, n_iter=5,\n",
       "                              random_state=None, tol=0.0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), TruncatedSVD())\n",
    "\n",
    "pipeline.fit(X_train['title'].append(X_train['text'], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the more complicated features, some of which rely on pre-trained models that are part of packages like nltk or sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POS(TransformPrimitive):\n",
    "    \"\"\"Computes the number of each of the most common parts of speech used\n",
    "       in a document/string\"\"\"\n",
    "    \n",
    "    name=\"POS_count\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    number_output_features=15\n",
    "    \n",
    "    def get_function(self):\n",
    "        def pos(array):\n",
    "            li = [nltk.pos_tag(helpers.clean_tokens(x)) for x in array]\n",
    "            types = ['C', 'D', 'E', 'F', 'I', 'J',\n",
    "                     'L', 'M', 'N', 'P', 'R', 'T',\n",
    "                     'U', 'V', 'W']\n",
    "            type_arr = []\n",
    "            for row in li:\n",
    "                fd = nltk.FreqDist([b[0] for (a,b) in row])\n",
    "                type_arr.append([fd[i] for i in types])\n",
    "            return np.array(type_arr).T\n",
    "        return pos\n",
    "    \n",
    "class DiversityScore(TransformPrimitive):\n",
    "    \"\"\"Computes the diverity of words used in a document/string\"\"\"\n",
    "    \n",
    "    name=\"Diversity\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def diversity(array): \n",
    "            ret = []\n",
    "            for x in array:\n",
    "                y = helpers.clean_tokens(x)\n",
    "                if len(y) < 1:\n",
    "                    ret.append(0)\n",
    "                else:\n",
    "                    ret.append(len(set(y))/len(y))           \n",
    "            return ret\n",
    "        return diversity\n",
    "    \n",
    "class PolarityScore(TransformPrimitive):\n",
    "    \"\"\"Computes the percieved positivity(1) or negativity(-1) score of\n",
    "       a document/string\"\"\"\n",
    "    \n",
    "    name=\"Polarity\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    \n",
    "    def get_function(self):\n",
    "        def polarity(array):\n",
    "            vader = SentimentIntensityAnalyzer()\n",
    "            def vader_pol(sentence):\n",
    "                return (vader.polarity_scores(sentence)['pos'] - \n",
    "                       vader.polarity_scores(sentence)['neg'])\n",
    "            return [vader_pol(dtk.detokenize(helpers.clean_tokens(x))) for x in array]\n",
    "        return polarity\n",
    "\n",
    "class LSA(TransformPrimitive):\n",
    "    \"\"\"Computes the latent semantic analysis of a document/string\"\"\"\n",
    "    \n",
    "    name=\"LSA\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    number_output_features=2\n",
    "    \n",
    "    def get_function(self):\n",
    "        def lsa(array):\n",
    "            array = array.apply(lambda x: dtk.detokenize(helpers.clean_tokens(x)))\n",
    "            return np.array(pipeline.transform(array)).T\n",
    "        return lsa\n",
    "\n",
    "class USE(TransformPrimitive):\n",
    "    \"\"\"Computes the latent semantic analysis of a document/string\"\"\"\n",
    "    \n",
    "    name=\"USE\"\n",
    "    input_types=[vtypes.Text]\n",
    "    return_type=vtypes.Numeric\n",
    "    number_output_features=512\n",
    "    \n",
    "    def get_function(self):\n",
    "        def use(array):\n",
    "            array = array.apply(lambda x: dtk.detokenize(helpers.clean_tokens(x)))\n",
    "            with tf.Session() as session:\n",
    "                session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "                message_embeddings = session.run(embed(array.tolist()))\n",
    "            return np.array(message_embeddings).T\n",
    "        return use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Create Feature Matrices\n",
    "Here we choose the features we wish to include in the training (in this case all of them), and calculate the training feature matrix. We have set the chunk size to the size of the training set, because the \"USE\" or Universal Sentence Encoding Feature takes a disproporionately long time to run if calculated in chunks rather than all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 21 features\n",
      "Elapsed: 22:19 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 1/1 chunks\n"
     ]
    }
   ],
   "source": [
    "trans = [TitleCount, \n",
    "         PunctuationCount,\n",
    "         StopWordCount,\n",
    "         CapitalCount,\n",
    "         WordCount, \n",
    "         POS,\n",
    "         DiversityScore,\n",
    "         PolarityScore,\n",
    "         LSA,\n",
    "         USE]\n",
    "\n",
    "chunk_size_train = estrain['reviews'].shape[0]\n",
    "\n",
    "train_feature_matrix, features = ft.dfs(entityset=estrain,\n",
    "                              target_entity='reviews',\n",
    "                              trans_primitives=trans,\n",
    "                              verbose=True,\n",
    "                              chunk_size=chunk_size_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the features of the test set, using the same chunk size method to optimize runtime for the \"USE\" primitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 04:47 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 1/1 chunks\n"
     ]
    }
   ],
   "source": [
    "chunk_size_test = estest['reviews'].shape[0]\n",
    "\n",
    "test_feature_matrix = ft.calculate_feature_matrix(features=features,\n",
    "                                                  entityset=estest,\n",
    "                                                  verbose=True,\n",
    "                                                  chunk_size=chunk_size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reindex the test and training feature matrix to ensure that the train and test labels match the indices of the train and test feature matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_matrix = train_feature_matrix.reindex(y_train.index)\n",
    "test_feature_matrix = test_feature_matrix.reindex(y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Machine Learning\n",
    "Here we create and test various machine learning models from sklearn on the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.636734693877551"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "lgr.fit(train_feature_matrix, y_train)\n",
    "lgr.score(test_feature_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521541950113379"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgbc = HistGradientBoostingClassifier()\n",
    "hgbc.fit(train_feature_matrix, y_train)\n",
    "hgbc.score(test_feature_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5628117913832199"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, class_weight = \"balanced\", n_jobs=-1)\n",
    "rfc.fit(train_feature_matrix, y_train)\n",
    "rfc.score(test_feature_matrix, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can observe the feature importances for this model, and see that the Universal Sentence Encoder features and the polarity score are the most influential in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USE(text)__28</td>\n",
       "      <td>0.014496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLARITY(title)</td>\n",
       "      <td>0.012911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USE(text)__289</td>\n",
       "      <td>0.012232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USE(text)__149</td>\n",
       "      <td>0.011035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USE(title)__328</td>\n",
       "      <td>0.010571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USE(text)__452</td>\n",
       "      <td>0.007943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USE(title)__289</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POLARITY(text)</td>\n",
       "      <td>0.007335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USE(title)__415</td>\n",
       "      <td>0.006484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USE(title)__28</td>\n",
       "      <td>0.006322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "0    USE(text)__28  0.014496\n",
       "1  POLARITY(title)  0.012911\n",
       "2   USE(text)__289  0.012232\n",
       "3   USE(text)__149  0.011035\n",
       "4  USE(title)__328  0.010571\n",
       "5   USE(text)__452  0.007943\n",
       "6  USE(title)__289  0.007905\n",
       "7   POLARITY(text)  0.007335\n",
       "8  USE(title)__415  0.006484\n",
       "9   USE(title)__28  0.006322"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\"name\", \"score\"]\n",
    "values = pd.DataFrame(sorted(zip(train_feature_matrix.columns, rfc.feature_importances_), key=lambda x: x[1] * -1))\n",
    "\n",
    "values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4766439909297052"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb = bnb.fit(train_feature_matrix, y_train)\n",
    "bnb.score(test_feature_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot = VotingClassifier(voting='soft', estimators=[('lgr', lgr), ('rfc', rfc), ('hgbc', hgbc)], weights=[3, 1, 6])\n",
    "vot.fit(train_feature_matrix, y_train)\n",
    "vot.score(test_feature_matrix, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the highest score we can get with a model is around 65%, which seems like a pretty poor result. However, given that it is a 5 class classification problem, it is not a horrible score. Furthermore, we can look at the confusion matrix to see where the model goes wrong, and how far off the answer the model is when it is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_confusion_matrix(y_test, \n",
    "                      vot.predict(test_feature_matrix), \n",
    "                      ['1', '2', '3', '4', '5'], \n",
    "                      normalize=True, \n",
    "                      title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1404a4e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y_train, palette = sns.cubehelix_palette(8, start=1, rot=-.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16ece7470>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y_test, palette = sns.cubehelix_palette(8, start=1, rot=-.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from looking at the confusion matrix, it is clear that the model is pretty accurate, and when it predicts the star rating wrong, it is likely within one star of the correct answer, which is much better than a model that has the same accuracy but then predicts the wrong ones as a star rating very wrong on average. Furthermore, as we can see, the predictions have about the same distribution of star ratings as the training data, which suggests that this model is pretty accurate, and doesn't just predict all of the test data to be in the most frequent category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "While this is an end-to-end example of going from raw text data to a machine learning model with Natural Language Processing Custom Primitives, it is necessary to do before this model would become something impactful. Ideally, in a problem such as this one, there would be more data available, especially pertaining to the customer who wrote each review, that would make the data structure more complicated, but also give the model more insight into patterns of each reviewer, so that it could make more accurate predictions. Luckily, Featuretools makes it easy to deal with relational datasets, and so this new extra data would not be too challenging to incorporate into this model.\n",
    "\n",
    "\n",
    "<p>\n",
    "    <img src=\"https://www.featurelabs.com/wp-content/uploads/2017/12/logo.png\" alt=\"Featuretools\" />\n",
    "</p>\n",
    "\n",
    "Featuretools was created by the developers at [Feature Labs](https://www.featurelabs.com/). If building impactful data science pipelines is important to you or your business, please [get in touch](https://www.featurelabs.com/contact/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
